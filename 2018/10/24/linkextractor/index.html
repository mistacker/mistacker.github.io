<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="四处漂泊，落叶归根。"><title>LinkExtractor的简单使用 | Mistacker|博客</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">LinkExtractor的简单使用</h1><a id="logo" href="/.">Mistacker|博客</a><p class="description">孤帆远影碧空尽，唯见长江天际流。</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/comments/"><i class="fa fa-comments"> 留言</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">LinkExtractor的简单使用</h1><div class="post-meta">Oct 24, 2018<span> | </span><span class="category"><a href="/categories/python/">python</a><a href="/categories/python/scrapy/">scrapy</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><p>&emsp;&emsp; 在爬取一个网站时，想要爬去的数据同场分布在多个页面中，每个页面包含一部分数据以及通向其他页面的链接；往往想要获取到我们想要的数据，就必须提取链接进行访问，提取链接可使用<code>Selector</code>和<code>LinkExtractor</code>两种方法，我们就后一种方法进行简单的使用说明，至于为什么使用<code>LinkExtractor</code>，当然是因为其在提取大量链接时更加方便。(<em>注：这里所说的爬取是指通过<code>scrapy</code>框架进行操作的，如果没有当然就需要安装了。</em>)</p>
<h4 id="下载通过一个简单的例子进行演示说明：-这里以起点免费作品页面进行演示"><a href="#下载通过一个简单的例子进行演示说明：-这里以起点免费作品页面进行演示" class="headerlink" title="下载通过一个简单的例子进行演示说明：(这里以起点免费作品页面进行演示)"></a>下载通过一个简单的例子进行演示说明：(这里以起点免费作品页面进行演示)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> scrapy shell -s USER_AGENT=<span class="string">"Mozilla/5.0"</span> <span class="string">'https://www.qidian.com/free/all'</span></span></span><br><span class="line">...</span><br><span class="line">2018-10-23 16:08:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.qidian.com/robots.txt&gt; (referer: None)</span><br><span class="line">2018-10-23 16:08:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.qidian.com/free/all&gt; (referer: None)</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x7f0458000390&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET https://www.qidian.com/free/all&gt;</span><br><span class="line">[s]   response   &lt;200 https://www.qidian.com/free/all&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x7f045694c780&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider 'default' at 0x7f04564d3c88&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update local objects </span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   view(response)    View response in a browser</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们以翻页为例，获取它的下一页链接，该页面是这样的：<br><img src="/images/qidian.png" alt=""><br>代码获取一下该翻页链接：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>le = LinkExtractor(restrict_css=<span class="string">'div[class="lbf-pagination"]&gt;ul&gt;li:last-child'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>links = le.extract_links(response)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>links[<span class="number">0</span>].url</span><br><span class="line"><span class="string">'https://www.qidian.com/free/all?orderId=&amp;vip=hidden&amp;style=1&amp;pageSize=20&amp;siteid=1&amp;pubflag=0&amp;hiddenField=1&amp;page=2'</span></span><br></pre></td></tr></table></figure></p>
<p>获取到的<code>url</code>就是下一页的<code>url</code>，下面我们就可以完成<code>Spider</code>的提取下一页链接的任务。</p>
<h2 id="简单创建一个爬虫项目："><a href="#简单创建一个爬虫项目：" class="headerlink" title="简单创建一个爬虫项目："></a>简单创建一个爬虫项目：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject qidian</span><br><span class="line">...</span><br><span class="line">$ cd qidian</span><br><span class="line">$ scrapy genspider qidianBook qidian.com</span><br><span class="line">Created spider <span class="string">'qidianBook'</span> using template <span class="string">'basic'</span> <span class="keyword">in</span> module:</span><br><span class="line">  qidian.spiders.qidianBook</span><br></pre></td></tr></table></figure>
<p>下面我们开始编写<code>spiders</code>中的<code>qidianBook.py</code>，针对这个项目，我们仅仅获取一下所有小说的书名、作者、分类、简介：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QidianbookSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'qidianBook'</span></span><br><span class="line">    allowed_domains = [<span class="string">'qidian.com'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'https://www.qidian.com/free/all?orderId=&amp;vip=hidden&amp;style=1&amp;pageSize=20&amp;siteid=1&amp;pubflag=0&amp;hiddenField=1&amp;page=1'</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        baseUrl = response.url</span><br><span class="line">        book_lis = response.xpath(<span class="string">'//ul[@class="all-img-list cf"]/li'</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> book_lis:</span><br><span class="line">            book_name = li.xpath(<span class="string">'.//h4/a/text()'</span>).extract_first()</span><br><span class="line">            book_author = li.xpath(<span class="string">'.//p[@class="author"]/a[@class="name"]/text()'</span>).extract_first()</span><br><span class="line">            book_type = <span class="string">'*'</span>.join(li.css(<span class="string">'p[class="author"]&gt;a:nth-child(4)::text,a:nth-child(6)::text'</span>).extract())</span><br><span class="line">            item = &#123;</span><br><span class="line">                <span class="string">'书名：'</span>: book_name,</span><br><span class="line">                <span class="string">'作者：'</span>: book_author,</span><br><span class="line">                <span class="string">'类型：'</span>: book_type,</span><br><span class="line">            &#125;</span><br><span class="line">            url = li.css(<span class="string">'h4&gt;a::attr("href")'</span>).extract_first()</span><br><span class="line">            complete_url = urljoin(baseUrl, url)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(complete_url, callback=self.get_intro, meta=&#123;<span class="string">'item'</span>: item&#125;)</span><br><span class="line"></span><br><span class="line">        le = LinkExtractor(restrict_css=<span class="string">'div[class="lbf-pagination"]&gt;ul&gt;li:last-child'</span>)</span><br><span class="line">        links = le.extract_links(response)</span><br><span class="line">        <span class="keyword">if</span> links:</span><br><span class="line">            next_url = links[<span class="number">0</span>].url</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_intro</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = response.meta[<span class="string">'item'</span>]</span><br><span class="line">        intro = response.css(<span class="string">'div[class="book-intro"]&gt;p::text'</span>).extract_first().replace(<span class="string">' '</span>, <span class="string">''</span>).replace(<span class="string">'\r'</span>, <span class="string">''</span>).replace(<span class="string">'\u3000'</span>, <span class="string">' '</span>)</span><br><span class="line">        item[<span class="string">'简介：'</span>] = intro</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<p>然后我们执行这个爬虫，执行之前可以在<code>settings</code>中添加一个<code>USER_AGENT</code>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT = <span class="string">'Mozilla/5.0 (X11; Ubuntu; Linu…) Gecko/20100101 Firefox/62.0'</span></span><br></pre></td></tr></table></figure></p>
<p>执行，并把结果保存到<code>qidian.json</code>中：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> scrapy crawl qidianBook -o qidian.json -s FEED_EXPORT_ENCODING=utf-8</span></span><br></pre></td></tr></table></figure></p>
<p>你可得有心理准备，这一运行，就会把所有书爬下来。<br>之后你就可以查看<code>qidian.json</code>文件里的内容了：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat qidian.json</span></span><br><span class="line">[</span><br><span class="line">&#123;"书名：": "神级生灵", "作者：": "魔动", "类型：": "玄幻*东方玄幻", "简介：": "  穿越不是神话，这是龙炅的座右铭，也只是座右铭！"&#125;,</span><br><span class="line">&#123;"书名：": "云穹之未来断点", "作者：": "骷髅精灵", "类型：": "科幻*未来世界", "简介：": "  异族入侵太阳系，血狼战队队长莫峰在一场惨烈的会战之后回到了末日之前，他能否解开谜团，改变身边亲人朋友的命运……"&#125;,</span><br><span class="line">&#123;"书名：": "最遥远的南边", "作者：": "哦罗罗", "类型：": "现实*成功励志", "简介：": "  几十个英文单词储备就远赴海外，是头脑发热还是......？"&#125;,</span><br><span class="line">&#123;"书名：": "保持匿名", "作者：": "莫远遥", "类型：": "现实*现实百态", "简介：": "  突然发现至少20个字的介绍不知该说些什么，其实，连作品类型，我也不确切我选对没有，它当然和“玄幻”“奇幻”“武侠”“仙侠”“军事”“历史”“游戏”“体育”“灵异”“女生”“二次元”这类无关，天，完全不入流的啊，还有谁会看，“科幻”的话，应该也不算，那就只剩下都市和职场了，可是，那些奇人神人离奇幻想狗血剧情，我实在不会啊，也罢也罢，怎么说，小说背景也算是在都市吧，那作品类型就选“都市”吧，可是子类“异术超能”“恩怨情仇”“青春校园”……果然，大家都爱看些充满幻想的东西，算了算了，随意选吧，就当，这里是我一个人的菜园子，每天来浇点水松松土种种菜，也就不求有人问津了。"&#125;,</span><br><span class="line">&#123;"书名：": "开天录", "作者：": "血红", "类型：": "玄幻*东方玄幻", "简介：": "  生存，很容易。"&#125;,</span><br><span class="line">&#123;"书名：": "红砖街轶事", "作者：": "李安云", "类型：": "现实*现实百态", "简介：": "  一条闹中取静、建筑独特的老街"&#125;,</span><br><span class="line">......</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p><code>LinkExtractor</code>的使用更方便的获取打了下一页的链接，代码简洁，这仅仅是其一种方式的使用，更多参数请参考<a href="https://doc.scrapy.org/en/latest/topics/link-extractors.html" target="_blank" rel="noopener">Link Extractors</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://mistacker.github.io/2018/10/24/linkextractor/" data-id="cjoewdpg8001c9x6innc78ro1" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACLElEQVR42u3au27DMBAEQP//TytAqhSWvEsqBkQOK8MPyaNicXfk6xWv43edvf/307PX+ffP7nXDwsDAeCzjuFxn38mvmZDy+57+BwwMjA0Y1yF7fYnkT1+/f8N1MDAwMALSdRzn0YmBgYExz2iLwvyaXw1cDAyMBzKSZvJe0vXd/7EXx8DAeCCj3Rj45ut/3N/AwMB4COMo13WMjkV2u2Hw5voYGBhLM5LxWX78Iv9++9uo3MTAwFiU0R6taIO4bUcHN00xMDC2YeSR2o7v86jNtwowMDD2YbRt5HUsti3ozCTtNfbUMTAwHs7IB2p3jc/aK0eBi4GBsRyjLe/av5I/oLzpPW1iMTAwlmYkY/rvtKztlgAGBsYOjDbsiuHXxJmusZEfBgbG2ox8M3Ks1UyKwhsiGwMDYxtGG3ljxeL8YQsMDIydGUmxOBOOY01scdgCAwNjOUa+JTkfyjOHKj600xgYGJsx8vFZfjgjweRBfLq/gYGBsShjsJYsx2TtNsNM0GNgYKzHyC86NkobG7HlIYuBgbEbY6wEzIvCtnwsSBgYGEszxo5nDR6GmF5RqYqBgbEc4yjXGKx9om2Li4GBsTajDbv2CEVbIOaBjoGBsRsjH9m3TW8SjmNjuzf3wsDA2IBRj+MnSr1iTzV4TBgYGBgzJV1S2LWkD6UhBgYGRhzB7a9uSE4MDIwNGG0TO9as5pHatrgYGBhrM8Zax5aax+vY1gIGBsaijB9+jhQZiqomdwAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/linkextractor/">linkextractor</a></div><div class="post-nav"><a class="pre" href="/2018/11/01/docker/">Docker的使用</a><a class="next" href="/2018/10/23/bs4_and_lxml/">网页爬虫---html的遍历</a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zOTk4Ny8xNjUxNA=="><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');
</script></div></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><input class="st-default-search-input" placeholder="Search" type="text"/></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/URL/">URL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/python/flask/">flask</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/scrapy/">scrapy</a></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/bs4/" style="font-size: 15px;">bs4</a> <a href="/tags/celery/" style="font-size: 15px;">celery</a> <a href="/tags/nginx/" style="font-size: 15px;">nginx</a> <a href="/tags/mongodb/" style="font-size: 15px;">mongodb</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/osroom/" style="font-size: 15px;">osroom</a> <a href="/tags/习题/" style="font-size: 15px;">习题</a> <a href="/tags/HTML遍历/" style="font-size: 15px;">HTML遍历</a> <a href="/tags/lxml/" style="font-size: 15px;">lxml</a> <a href="/tags/email/" style="font-size: 15px;">email</a> <a href="/tags/多线程/" style="font-size: 15px;">多线程</a> <a href="/tags/WSGI/" style="font-size: 15px;">WSGI</a> <a href="/tags/linkextractor/" style="font-size: 15px;">linkextractor</a> <a href="/tags/RESTful-api/" style="font-size: 15px;">RESTful-api</a> <a href="/tags/tkinter/" style="font-size: 15px;">tkinter</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/信号/" style="font-size: 15px;">信号</a> <a href="/tags/blinker/" style="font-size: 15px;">blinker</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/11/01/docker/">Docker的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/24/linkextractor/">LinkExtractor的简单使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/23/bs4_and_lxml/">网页爬虫---html的遍历</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/16/design/">一个设计签名的小程序</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/osroom/">OSROOM安装使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/14/signal/">Flask中的信号</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/problem/">一些练习题</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/email/">电子邮件</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/wsgi/">WSGI的介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/celery/">Celery的介绍</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.yangqq.com/" title="杨青个人博客" target="_blank">杨青个人博客</a><ul></ul><a href="https://www.oschina.net/project" title="开源中国项目" target="_blank">开源中国项目</a><ul></ul><a href="http://www.haowenbo.com/" title="Easy Blog" target="_blank">Easy Blog</a><ul></ul><a href="wxyblog.top" title="王旭阳的技术专栏" target="_blank">王旭阳的技术专栏</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Mistacker|博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://mistacker.github.io"> Mistacker | 个人专属</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script>(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
_st('install','cxRJFkZr9xPGAhZDVN82','2.0.0');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/haru02.model.json"},"display":{"position":"right","width":120,"height":240},"mobile":{"show":true},"log":false});</script></body></html>